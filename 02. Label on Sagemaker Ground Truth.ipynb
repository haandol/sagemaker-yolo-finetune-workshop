{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 Finetuning on AWS\n",
    "\n",
    "This series of notebooks demonstrates how to finetune pretrained YOLO v3 (aka YOLO3) using MXNet on AWS.\n",
    "\n",
    "**This notebook** walks through using the [SageMaker Ground Truth](https://aws.amazon.com/sagemaker/groundtruth/) tool to annotate training and validation data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow-on** the content of the notebooks shows:\n",
    "\n",
    "* How to use MXNet YOLO3 pretrained model\n",
    "* How to use Deep SORT with MXNet YOLO3\n",
    "* How to create Ground-Truth dataset from images the model mis-detected\n",
    "* How to finetune the model using the created dataset\n",
    "* Load your finetuned model and Deploy Sagemaker-Endpoint with it using CPU instance.\n",
    "* Load your finetuned model and Deploy Sagemaker-Endpoint with it using GPU instance.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook is designed to be run in Amazon SageMaker. To run it (and understand what's going on), you'll need:\n",
    "\n",
    "* Basic familiarity with Python, [MXNet](https://mxnet.apache.org/), [AWS S3](https://docs.aws.amazon.com/s3/index.html), [Amazon Sagemaker](https://aws.amazon.com/sagemaker/)\n",
    "* To create an **S3 bucket** in the same region, and ensure the SageMaker notebook's role has access to this bucket.\n",
    "* Sufficient [SageMaker quota limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_sagemaker) set on your account to run GPU-accelerated spot training jobs.\n",
    "\n",
    "## Cost and runtime\n",
    "\n",
    "Depending on your configuration, this demo may consume resources outside of the free tier but should not generally be expensive because we'll be training on a small number of images. You might wish to review the following for your region:\n",
    "\n",
    "* [Amazon SageMaker pricing](https://aws.amazon.com/sagemaker/pricing/)\n",
    "* [SageMaker Ground Truth pricing](https://aws.amazon.com/sagemaker/groundtruth/pricing/)\n",
    "\n",
    "The standard `ml.t2.medium` instance should be sufficient to run the notebooks.\n",
    "\n",
    "We will use GPU-accelerated instance types for training and hyperparameter optimization, and use spot instances where appropriate to optimize these costs.\n",
    "\n",
    "As noted in the step-by-step guidance, you should take particular care to delete any created SageMaker real-time prediction endpoints when finishing the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Dependencies and configuration\n",
    "\n",
    "As usual we'll start by loading libraries, defining configuration, and connecting to the AWS SDKs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Built-Ins:\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import imageio\n",
    "import sagemaker\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'BUCKET_NAME' (str)\n",
      "Stored 'REGION' (str)\n",
      "Stored 'IMAGE_PREFIX' (str)\n",
      "Stored 'MODELS_PREFIX' (str)\n",
      "Stored 'CLASS_NAMES' (list)\n",
      "Stored 'BATCH_NAME' (str)\n"
     ]
    }
   ],
   "source": [
    "BUCKET_NAME = sagemaker.Session().default_bucket()\n",
    "%store BUCKET_NAME\n",
    "\n",
    "REGION = sagemaker.Session().boto_region_name\n",
    "%store REGION\n",
    "\n",
    "IMAGE_PREFIX = 'images'\n",
    "%store IMAGE_PREFIX\n",
    "\n",
    "MODELS_PREFIX = 'models'\n",
    "%store MODELS_PREFIX\n",
    "\n",
    "CLASS_NAMES = ['person']\n",
    "%store CLASS_NAMES\n",
    "\n",
    "BATCH_NAME = 'yolo-workshop-batch'\n",
    "%store BATCH_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "smclient = session.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-ap-northeast-2-929831892372\n"
     ]
    }
   ],
   "source": [
    "print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 1: Create bucket\n",
    "\n",
    "In this notebook, we are going to label the mis-detected images using Sagemaker Ground Truth.\n",
    "\n",
    "Most of the Sagemaker services are needed the data on the S3 to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket have been already created..\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    bucket.create(\n",
    "        ACL='private',\n",
    "        CreateBucketConfiguration={\n",
    "            'LocationConstraint': REGION,\n",
    "        },\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'BucketAlreadyOwnedByYou':\n",
    "        print('Bucket have been already created..')\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'CD6C26699D976BE5',\n",
       "  'HostId': 'Kvw4olpwumeNkR7xaEks8FlK4/We4QKPTDpGJuOzgFKts2pegWQBsxgy8SY1UWJfwwe3UN4jwtY=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'Kvw4olpwumeNkR7xaEks8FlK4/We4QKPTDpGJuOzgFKts2pegWQBsxgy8SY1UWJfwwe3UN4jwtY=',\n",
       "   'x-amz-request-id': 'CD6C26699D976BE5',\n",
       "   'date': 'Mon, 16 Mar 2020 07:20:23 GMT',\n",
       "   'content-length': '0',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set cors to bucket\n",
    "\n",
    "cors_config = {\n",
    "    'CORSRules': [{\n",
    "        'AllowedHeaders': ['Authorization'],\n",
    "        'AllowedMethods': ['GET', 'PUT'],\n",
    "        'AllowedOrigins': ['*'],\n",
    "        'ExposeHeaders': ['GET', 'PUT'],\n",
    "    }]\n",
    "}\n",
    "cors = bucket.Cors()\n",
    "cors.put(CORSConfiguration=cors_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload images to S3\n",
    "\n",
    "Let's say the mis-detected images are stored at `/Users/dongkyl/Documents/git/mxnet-deepsort-yolo3/images`, below code will upload your images onto S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dongkyl/Documents/git/mxnet-deepsort-yolo3/images\n"
     ]
    }
   ],
   "source": [
    "local_image_path = '/Users/dongkyl/Documents/git/mxnet-deepsort-yolo3/images'\n",
    "print(local_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on S3, the path for images would be `/{BATCH_NAME}/{IMAGE_PREFIX}`. \n",
    "\n",
    "By this, the `full s3 path` of the image will be `s3://{BUCKET_NAME}/{BATCH_NAME}/{IMAGE_PREFIX}/{FILENAME}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo-workshop-batch/images\n"
     ]
    }
   ],
   "source": [
    "upload_path = f'{BATCH_NAME}/{IMAGE_PREFIX}'\n",
    "print(upload_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to upload images to bucket to make `input.manifest` that is for Ground-Truth labeling job. And, of course, the images will also be used in finetuning too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded 235.jpg...\n",
      "uploaded 88.jpg...\n",
      "uploaded 256.jpg...\n",
      "uploaded 349.jpg...\n",
      "uploaded 136.jpg...\n",
      "uploaded 112.jpg...\n",
      "uploaded 328.jpg...\n",
      "uploaded 274.jpg...\n",
      "uploaded 217.jpg...\n",
      "uploaded 352.jpg...\n",
      "uploaded 250.jpg...\n",
      "uploaded 292.jpg...\n",
      "uploaded 148.jpg...\n",
      "uploaded 130.jpg...\n",
      "uploaded 268.jpg...\n",
      "uploaded 196.jpg...\n",
      "uploaded 76.jpg...\n",
      "uploaded 316.jpg...\n",
      "uploaded 154.jpg...\n",
      "uploaded 94.jpg...\n",
      "uploaded 229.jpg...\n",
      "uploaded 310.jpg...\n",
      "uploaded 244.jpg...\n",
      "uploaded 346.jpg...\n",
      "uploaded 286.jpg...\n",
      "uploaded 124.jpg...\n",
      "uploaded 262.jpg...\n",
      "uploaded 100.jpg...\n",
      "uploaded 340.jpg...\n",
      "uploaded 280.jpg...\n",
      "uploaded 106.jpg...\n",
      "uploaded 223.jpg...\n",
      "uploaded 160.jpg...\n",
      "uploaded 322.jpg...\n",
      "uploaded 118.jpg...\n",
      "uploaded 304.jpg...\n",
      "uploaded 82.jpg...\n",
      "uploaded 202.jpg...\n",
      "uploaded 298.jpg...\n",
      "uploaded 142.jpg...\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "\n",
    "for file_path in glob(f'{local_image_path}/missed-*.jpg'):\n",
    "    # we are going to label on entire scene, not detected area\n",
    "    file_path = re.sub(r'missed-(\\d+)-\\d+', 'orig-\\\\1', file_path)\n",
    "    \n",
    "    filename = file_path.replace('orig-', '').rsplit('/', 1)[-1]\n",
    "    bucket.upload_file(file_path, f'{upload_path}/{filename}')\n",
    "    filenames.append(filename)\n",
    "    print(f'uploaded {filename}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate input.manifest\n",
    "\n",
    "In order to set up the Sagemaker Ground Truth labeling job, you should make a manifest file that contains the list of the files on S3.\n",
    "\n",
    "The [**manifest**](https://docs.aws.amazon.com/sagemaker/latest/dg/sms-data-input.html) file is just list of dictionaries and each row must contain one of the key `source-ref`. `source-ref` value is going to be the `full s3 path` of the image file, that is mentioned above.\n",
    "\n",
    "We are going to generate input manifest and place it into `{BATCH_NAME}/manifests/input.manifest`. And then upload it onto S3 bucket with same path. \n",
    "\n",
    "The full path for manifest would be `s3://{BUCKET_NAME}/{BATCH_NAME}/manifests/input.manifest`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{BATCH_NAME}/manifests', exist_ok=True)\n",
    "input_manifest_loc = f'{BATCH_NAME}/manifests/input.manifest'\n",
    "\n",
    "with open(input_manifest_loc, 'w') as fp:\n",
    "    for filename in filenames:\n",
    "        source_ref = f's3://{bucket.name}/{upload_path}/{filename}'\n",
    "        fp.write(json.dumps({'source-ref': source_ref})+'\\n')\n",
    "\n",
    "bucket.upload_file(input_manifest_loc, input_manifest_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visit the [**AWS S3 Console**](https://s3.console.aws.amazon.com/) to make sure images are uploaded successfully.\n",
    "\n",
    "Of course, you can display the list of files on the notebook using boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo-workshop-batch/images/100-2.jpg\n",
      "yolo-workshop-batch/images/100.jpg\n",
      "yolo-workshop-batch/images/106-2.jpg\n",
      "yolo-workshop-batch/images/106.jpg\n",
      "yolo-workshop-batch/images/112-2.jpg\n",
      "yolo-workshop-batch/images/112.jpg\n",
      "yolo-workshop-batch/images/118-2.jpg\n",
      "yolo-workshop-batch/images/118.jpg\n",
      "yolo-workshop-batch/images/124-2.jpg\n",
      "yolo-workshop-batch/images/124.jpg\n",
      "yolo-workshop-batch/images/130-2.jpg\n",
      "yolo-workshop-batch/images/130.jpg\n",
      "yolo-workshop-batch/images/136-2.jpg\n",
      "yolo-workshop-batch/images/136.jpg\n",
      "yolo-workshop-batch/images/142-2.jpg\n",
      "yolo-workshop-batch/images/142.jpg\n",
      "yolo-workshop-batch/images/148-2.jpg\n",
      "yolo-workshop-batch/images/148.jpg\n",
      "yolo-workshop-batch/images/154-2.jpg\n",
      "yolo-workshop-batch/images/154.jpg\n",
      "yolo-workshop-batch/images/160-2.jpg\n",
      "yolo-workshop-batch/images/160.jpg\n",
      "yolo-workshop-batch/images/196-3.jpg\n",
      "yolo-workshop-batch/images/196.jpg\n",
      "yolo-workshop-batch/images/202-3.jpg\n",
      "yolo-workshop-batch/images/202.jpg\n",
      "yolo-workshop-batch/images/217-3.jpg\n",
      "yolo-workshop-batch/images/217.jpg\n",
      "yolo-workshop-batch/images/223-3.jpg\n",
      "yolo-workshop-batch/images/223.jpg\n",
      "yolo-workshop-batch/images/229-3.jpg\n",
      "yolo-workshop-batch/images/229.jpg\n",
      "yolo-workshop-batch/images/235-3.jpg\n",
      "yolo-workshop-batch/images/235.jpg\n",
      "yolo-workshop-batch/images/244-1.jpg\n",
      "yolo-workshop-batch/images/244.jpg\n",
      "yolo-workshop-batch/images/250-1.jpg\n",
      "yolo-workshop-batch/images/250.jpg\n",
      "yolo-workshop-batch/images/256-1.jpg\n",
      "yolo-workshop-batch/images/256.jpg\n",
      "yolo-workshop-batch/images/262-1.jpg\n",
      "yolo-workshop-batch/images/262.jpg\n",
      "yolo-workshop-batch/images/268-1.jpg\n",
      "yolo-workshop-batch/images/268.jpg\n",
      "yolo-workshop-batch/images/274-1.jpg\n",
      "yolo-workshop-batch/images/274.jpg\n",
      "yolo-workshop-batch/images/280-1.jpg\n",
      "yolo-workshop-batch/images/280.jpg\n",
      "yolo-workshop-batch/images/286-1.jpg\n",
      "yolo-workshop-batch/images/286.jpg\n",
      "yolo-workshop-batch/images/292-1.jpg\n",
      "yolo-workshop-batch/images/292.jpg\n",
      "yolo-workshop-batch/images/298-1.jpg\n",
      "yolo-workshop-batch/images/298.jpg\n",
      "yolo-workshop-batch/images/304-1.jpg\n",
      "yolo-workshop-batch/images/304.jpg\n",
      "yolo-workshop-batch/images/310-1.jpg\n",
      "yolo-workshop-batch/images/310.jpg\n",
      "yolo-workshop-batch/images/316-1.jpg\n",
      "yolo-workshop-batch/images/316.jpg\n",
      "yolo-workshop-batch/images/322-1.jpg\n",
      "yolo-workshop-batch/images/322.jpg\n",
      "yolo-workshop-batch/images/328-1.jpg\n",
      "yolo-workshop-batch/images/328.jpg\n",
      "yolo-workshop-batch/images/340-6.jpg\n",
      "yolo-workshop-batch/images/340.jpg\n",
      "yolo-workshop-batch/images/346-6.jpg\n",
      "yolo-workshop-batch/images/346.jpg\n",
      "yolo-workshop-batch/images/349-3.jpg\n",
      "yolo-workshop-batch/images/349.jpg\n",
      "yolo-workshop-batch/images/352-6.jpg\n",
      "yolo-workshop-batch/images/352.jpg\n",
      "yolo-workshop-batch/images/76-2.jpg\n",
      "yolo-workshop-batch/images/76.jpg\n",
      "yolo-workshop-batch/images/82-2.jpg\n",
      "yolo-workshop-batch/images/82.jpg\n",
      "yolo-workshop-batch/images/88-2.jpg\n",
      "yolo-workshop-batch/images/88.jpg\n",
      "yolo-workshop-batch/images/94-2.jpg\n",
      "yolo-workshop-batch/images/94.jpg\n",
      "yolo-workshop-batch/images/orig-100.jpg\n",
      "yolo-workshop-batch/images/orig-106.jpg\n",
      "yolo-workshop-batch/images/orig-112.jpg\n",
      "yolo-workshop-batch/images/orig-118.jpg\n",
      "yolo-workshop-batch/images/orig-124.jpg\n",
      "yolo-workshop-batch/images/orig-130.jpg\n",
      "yolo-workshop-batch/images/orig-136.jpg\n",
      "yolo-workshop-batch/images/orig-142.jpg\n",
      "yolo-workshop-batch/images/orig-148.jpg\n",
      "yolo-workshop-batch/images/orig-154.jpg\n",
      "yolo-workshop-batch/images/orig-160.jpg\n",
      "yolo-workshop-batch/images/orig-196.jpg\n",
      "yolo-workshop-batch/images/orig-202.jpg\n",
      "yolo-workshop-batch/images/orig-217.jpg\n",
      "yolo-workshop-batch/images/orig-223.jpg\n",
      "yolo-workshop-batch/images/orig-229.jpg\n",
      "yolo-workshop-batch/images/orig-235.jpg\n",
      "yolo-workshop-batch/images/orig-244.jpg\n",
      "yolo-workshop-batch/images/orig-250.jpg\n",
      "yolo-workshop-batch/images/orig-256.jpg\n",
      "yolo-workshop-batch/images/orig-262.jpg\n",
      "yolo-workshop-batch/images/orig-268.jpg\n",
      "yolo-workshop-batch/images/orig-274.jpg\n",
      "yolo-workshop-batch/images/orig-280.jpg\n",
      "yolo-workshop-batch/images/orig-286.jpg\n",
      "yolo-workshop-batch/images/orig-292.jpg\n",
      "yolo-workshop-batch/images/orig-298.jpg\n",
      "yolo-workshop-batch/images/orig-304.jpg\n",
      "yolo-workshop-batch/images/orig-310.jpg\n",
      "yolo-workshop-batch/images/orig-316.jpg\n",
      "yolo-workshop-batch/images/orig-322.jpg\n",
      "yolo-workshop-batch/images/orig-328.jpg\n",
      "yolo-workshop-batch/images/orig-340.jpg\n",
      "yolo-workshop-batch/images/orig-346.jpg\n",
      "yolo-workshop-batch/images/orig-349.jpg\n",
      "yolo-workshop-batch/images/orig-352.jpg\n",
      "yolo-workshop-batch/images/orig-76.jpg\n",
      "yolo-workshop-batch/images/orig-82.jpg\n",
      "yolo-workshop-batch/images/orig-88.jpg\n",
      "yolo-workshop-batch/images/orig-94.jpg\n",
      "yolo-workshop-batch/manifests/input.manifest\n"
     ]
    }
   ],
   "source": [
    "for obj in bucket.objects.filter(Prefix=f'{BATCH_NAME}'):\n",
    "    print(obj.key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup Sagemker Ground Trutch Labeling workforce\n",
    "\n",
    "Sagemaker Ground Truth workforce gives you 3 options such as,\n",
    "\n",
    "- Amazon Mechanical Turk\n",
    "- Private\n",
    "- Vendor\n",
    "\n",
    "for more details, visit [**Use Amazon SageMaker Ground Truth for Labeling**](https://docs.aws.amazon.com/sagemaker/latest/dg/sms.html).\n",
    "\n",
    "In this notebook, We are going to use *Private Workforce* to label bounding boxes to our data. With Private workforce you can make your employees or contractors handling data within your organization.\n",
    "\n",
    "**in the [AWS console](https://console.aws.amazon.com)**,\n",
    "Under *Services* go to *Amazon SageMaker*, and select *Ground Truth > Labeling workforces* from the side-bar menu on the left. And select the *Private* tab on the top, click the button *Create private team* to create private workforce.\n",
    "\n",
    "<img src=\"Assets/PrivateWorkforce.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Creating workforce,\n",
    "\n",
    "- Private tab menu displays link under *Labeling portal sign-in URL*\n",
    "- Workers will got a email with temporary password\n",
    "\n",
    "When worker visit the link and login for the first time(with email as username and password as temporary password), worker has to reset the password.\n",
    "\n",
    "After resetting password, worker is finally ready to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Set up the SageMaker Ground Truth labeling job\n",
    "\n",
    "Now that our images and a manifest file listing them are ready in S3, we'll set up the Ground Truth labeling job **in the [AWS console](https://console.aws.amazon.com)**.\n",
    "\n",
    "Under *Services* go to *Amazon SageMaker*, and select *Ground Truth > Labeling Jobs* from the side-bar menu on the left.\n",
    "\n",
    "### Job Details\n",
    "\n",
    "Click the **Create labeling job** button, and you'll be asked to specify job details as follows:\n",
    "\n",
    "* **Job name:** Choose a name to identify this labeling job, e.g. `yolo-workshop-batch-0`\n",
    "* **Label name (The override checkbox):** Consider overriding this to `labels`\n",
    "* **Input data location:** The path to the input manifest file in S3 (see output above)\n",
    "* **Output data location:** The path to store labeled dataset in S3 (e.g.  *s3://{BUCKET_NAME}/{BATCH_NAME}/annotations*)\n",
    "* **IAM role:** If you're not sure whether your existing roles have the sufficient permissions for Ground Truth, select the options to create a new role\n",
    "* **Task type:** Image > Bounding box\n",
    "\n",
    "<img src=\"Assets/SetupGroundTruth.png\"/>\n",
    "\n",
    "All other settings can be left as default. Record your choices for the label name and output data location below, because we'll need these later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "job_name = 'yolo-job-0'\n",
    "%store job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intpu_dataset_location: s3://sagemaker-ap-northeast-2-929831892372/yolo-workshop-batch/manifests/input.manifest\n",
      "output_dataset_location: s3://sagemaker-ap-northeast-2-929831892372/annotations\n"
     ]
    }
   ],
   "source": [
    "print(f'intpu_dataset_location: s3://{bucket.name}/{input_manifest_loc}')\n",
    "print(f'output_dataset_location: s3://{bucket.name}/annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workers\n",
    "On the next screen, we'll configure who will annotate our data: Ground Truth allows you to define your own in-house Private Workforces; use Vendor Managed Workforces for specialist tasks; or use the public workforce provided by Amazon Mechanical Turk.\n",
    "\n",
    "Select Private worker type, and you'll be prompted either to select from your existing private workforces, or create a new one if none exist.\n",
    "\n",
    "To create a new private workforce if you need, simply follow the UI workflow with default settings. It doesn't matter what you call the workforce, and you can create a new Cognito User Group to define the workforce. Add yourself to the user pool by adding your email address: You should receive a confirmation email shortly with a temporary password and a link to access the annotation portal.\n",
    "\n",
    "Automatic data labeling is applicable only for data sets over 1000 samples, so leave this turned off for now.\n",
    "\n",
    "<img src=\"Assets/Workers.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling Tool\n",
    "Since you'll be labelling the data yourself, a brief description of the task should be fine in this case. When using real workforces, it's important to be really clear in this section about the task requirements and best practices - to ensure consistency of annotations between human workers.\n",
    "\n",
    "For example: In the common case where we see a pair of boots from the side and one is almost entirely obscured, how should the image be annotated? Should model cats count, or only real ones?\n",
    "\n",
    "The most important configuration here is to set the options to be the same as our CLASS_NAMES, we have only one label in this workshop *Person*.\n",
    "\n",
    "<img src=\"Assets/LabelingTool.png\" />\n",
    "\n",
    "Take some time to explore the other options for configuring the annotation tool; and when you're ready click \"Create\" to launch the labeling job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Label those images!\n",
    "\n",
    "Follow the link you received in your workforce invitation email to the workforce's **labeling portal**, and log in with the default password given in the email (which you'll be asked to change).\n",
    "\n",
    "If you lose the portal link, you can always retrieve it through the *Ground Truth > Labeling Workforces* menu in the SageMaker console: Near the top of the summary of private workforces.\n",
    "\n",
    "New jobs can sometimes take a minute or two to appear for workers. Select the job and click \"Start working\" to enter the labeling tool.\n",
    "\n",
    "<img src=\"Assets/WorkerLabelingJobs.png\"/>\n",
    "\n",
    "once the labeling job is started, you will see this labeling job web page..\n",
    "\n",
    "<img src=\"Assets/WorkerLabelingPage.png\"/>\n",
    "\n",
    "Note that you can check on the progress of labelling jobs through the APIs as well as in the AWS console.\n",
    "After few seconds from workers done their labeling job, the status will be changed to *Completed*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smclient.describe_labeling_job(LabelingJobName=job_name)['LabelingJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Check the labeling results\n",
    "\n",
    "when your workers done their job, *output.manifest* will be generated into following path.\n",
    "\n",
    "*s3://{BUCKET_NAME}/annotations/{job_name}/manifests/output/output.manifest*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': {'annotations': [{'class_id': 0,\n",
      "                             'height': 230,\n",
      "                             'left': 90,\n",
      "                             'top': 45,\n",
      "                             'width': 182},\n",
      "                            {'class_id': 0,\n",
      "                             'height': 231,\n",
      "                             'left': 150,\n",
      "                             'top': 0,\n",
      "                             'width': 174}],\n",
      "            'image_size': [{'depth': 3, 'height': 320, 'width': 427}]},\n",
      " 'labels-metadata': {'class-map': {'0': 'Person'},\n",
      "                     'creation-date': '2020-03-14T12:51:04.692288',\n",
      "                     'human-annotated': 'yes',\n",
      "                     'job-name': 'labeling-job/yolo-job-0',\n",
      "                     'objects': [{'confidence': 0.09}, {'confidence': 0.09}],\n",
      "                     'type': 'groundtruth/object-detection'},\n",
      " 'source-ref': 's3://sagemaker-ap-northeast-2-929831892372/yolo-workshop-batch/images/235.jpg'}\n"
     ]
    }
   ],
   "source": [
    "output_manifest_path = f'annotations/{job_name}/manifests/output/output.manifest'\n",
    "output_manifest_obj = bucket.Object(output_manifest_path)\n",
    "for el in map(json.loads, output_manifest_obj.get()['Body'].read().decode('utf-8').split('\\n')):\n",
    "    pprint(el)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, top level keys are 2, *source-ref* and *labels* respectively. the key *label* is the name you gave when setting up the labeling job. which is containing information of all bound-boxes about *source-ref* image.\n",
    "\n",
    "In next chapter, we will create Sagemaker Hyperparmeter Optimization(a.k.a HPO) Job with this *output.manifest*."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
