{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO v3 Finetuning on AWS\n",
    "\n",
    "This series of notebooks demonstrates how to finetune pretrained YOLO v3 (aka YOLO3) using MXNet on AWS.\n",
    "\n",
    "**This notebook** walks through using the [SageMaker Hyperparameter Tuning Job](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) tool to finding optmized hypterparameter and finetune the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow-on** the content of the notebooks shows:\n",
    "\n",
    "* How to use MXNet YOLO3 pretrained model\n",
    "* How to use Deep SORT with MXNet YOLO3\n",
    "* How to create Ground-Truth dataset from images the model mis-detected\n",
    "* How to finetune the model using the created dataset\n",
    "* Load your finetuned model and Deploy Sagemaker-Endpoint with it using CPU instance.\n",
    "* Load your finetuned model and Deploy Sagemaker-Endpoint with it using GPU instance.\n",
    "\n",
    "## Pre-requisites\n",
    "\n",
    "This notebook is designed to be run in Amazon SageMaker. To run it (and understand what's going on), you'll need:\n",
    "\n",
    "* Basic familiarity with Python, [MXNet](https://mxnet.apache.org/), [AWS S3](https://docs.aws.amazon.com/s3/index.html), [Amazon SageMaker](https://aws.amazon.com/sagemaker/)\n",
    "* To create an **S3 bucket** in the same region, and ensure the SageMaker notebook's role has access to this bucket.\n",
    "* Sufficient [SageMaker quota limits](https://docs.aws.amazon.com/general/latest/gr/aws_service_limits.html#limits_sagemaker) set on your account to run GPU-accelerated spot training jobs.\n",
    "\n",
    "## Cost and runtime\n",
    "\n",
    "Depending on your configuration, this demo may consume resources outside of the free tier but should not generally be expensive because we'll be training on a small number of images. You might wish to review the following for your region:\n",
    "\n",
    "* [Amazon SageMaker pricing](https://aws.amazon.com/sagemaker/pricing/)\n",
    "\n",
    "The standard `ml.t2.medium` instance should be sufficient to run the notebooks.\n",
    "\n",
    "We will use GPU-accelerated instance types for training and hyperparameter optimization, and use spot instances where appropriate to optimize these costs.\n",
    "\n",
    "As noted in the step-by-step guidance, you should take particular care to delete any created SageMaker real-time prediction endpoints when finishing the demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Dependencies and configuration\n",
    "\n",
    "As usual we'll start by loading libraries, defining configuration, and connecting to the AWS SDKs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dongkyl/.pyenv/versions/3.7.4/lib/python3.7/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "# Built-Ins:\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "import imageio\n",
    "import sagemaker\n",
    "import numpy as np\n",
    "from sagemaker.mxnet import MXNet\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore stored variables\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "s3 = session.resource('s3')\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "smclient = session.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client('iam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-ap-northeast-2-929831892372\n"
     ]
    }
   ],
   "source": [
    "print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Recap output.manifest\n",
    "\n",
    "In last notebook, we made the *output.manifest* that is containing annotation infromation along with image location. And here is the content of the file.\n",
    "\n",
    "content is dictionary having 2 essential keys, *labels* and *source-ref*. \n",
    "- **labels** - contains information of bounding boxes in the value under key *annotations*.  *class_id* is always *0* because we have only one class *person* in the dataset.\n",
    "- **source-ref** - same value as in *input.manifest* file\n",
    "\n",
    "For introduction to model training and deployment, see [**Train a Model with Amazon SageMaker**](http://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_manifest_path = f'annotations/{job_name}/manifests/output/output.manifest'\n",
    "output_manifest_obj = bucket.Object(output_manifest_path)\n",
    "dataset = output_manifest_obj.get()['Body'].read().decode('utf-8').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': {'annotations': [{'class_id': 0,\n",
      "                             'height': 383,\n",
      "                             'left': 61,\n",
      "                             'top': 32,\n",
      "                             'width': 105},\n",
      "                            {'class_id': 0,\n",
      "                             'height': 409,\n",
      "                             'left': 113,\n",
      "                             'top': 0,\n",
      "                             'width': 345},\n",
      "                            {'class_id': 0,\n",
      "                             'height': 97,\n",
      "                             'left': 33,\n",
      "                             'top': 151,\n",
      "                             'width': 36},\n",
      "                            {'class_id': 0,\n",
      "                             'height': 93,\n",
      "                             'left': 10,\n",
      "                             'top': 168,\n",
      "                             'width': 25}],\n",
      "            'image_size': [{'depth': 3, 'height': 416, 'width': 740}]},\n",
      " 'labels-metadata': {'class-map': {'0': 'Person'},\n",
      "                     'creation-date': '2020-05-20T03:37:13.245267',\n",
      "                     'human-annotated': 'yes',\n",
      "                     'job-name': 'labeling-job/yolo-workshop-job-0',\n",
      "                     'objects': [{'confidence': 0.09},\n",
      "                                 {'confidence': 0.09},\n",
      "                                 {'confidence': 0.09},\n",
      "                                 {'confidence': 0.09}],\n",
      "                     'type': 'groundtruth/object-detection'},\n",
      " 'source-ref': 's3://sagemaker-ap-northeast-2-929831892372/yolo-workshop-batch/images/88.jpg'}\n"
     ]
    }
   ],
   "source": [
    "pprint(json.loads(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Split dataset into Train and Test datasets\n",
    "\n",
    "Split dataset into train and test datasets is common procedure in Machine Learning(ML).\n",
    "\n",
    "There are several methods to do that, and we are going to use the simplest one in here. We are going to shuffle entire dataset and split with ratio of 9:1 for train and test respectively.\n",
    "\n",
    "After split, you will get 2 files, *train.manifest* and *test.manifest* in the path that *output.manifest* is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'n_samples_train' (int)\n",
      "Stored 'n_samples_test' (int)\n",
      "Training manifest uploaded to:\n",
      "s3://sagemaker-ap-northeast-2-929831892372/annotations/yolo-workshop-job-0/manifests/output/train.manifest\n",
      "Test manifest uploaded to:\n",
      "s3://sagemaker-ap-northeast-2-929831892372/annotations/yolo-workshop-job-0/manifests/output/test.manifest\n"
     ]
    }
   ],
   "source": [
    "TRAIN_RATIO = 0.9\n",
    "\n",
    "# shuffle dataset\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "n_samples_total = len(dataset)\n",
    "train_test_split_index = round(n_samples_total*TRAIN_RATIO)\n",
    "\n",
    "# split datasets\n",
    "train_dataset = dataset[:train_test_split_index]\n",
    "test_dataset = dataset[train_test_split_index:]\n",
    "\n",
    "n_samples_train = len(train_dataset)\n",
    "%store n_samples_train\n",
    "n_samples_test = len(test_dataset)\n",
    "%store n_samples_test\n",
    "\n",
    "# store manifests into localhost\n",
    "with open(f'train.manifest', 'w') as f:\n",
    "    for line in train_dataset:\n",
    "        if not line:\n",
    "            continue\n",
    "        f.write(str(line))\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "with open(f'test.manifest', 'w') as f:\n",
    "    for line in test_dataset:\n",
    "        if not line:\n",
    "            continue\n",
    "        f.write(str(line))\n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "# store train/test manifests to s3 bucket where output.manifest is located.\n",
    "manifest_path = output_manifest_path.rsplit('/', 1)[0]\n",
    "bucket.upload_file('train.manifest', f'{manifest_path}/train.manifest')\n",
    "print('Training manifest uploaded to:\\n' + f's3://{bucket.name}/{manifest_path}/train.manifest')\n",
    "bucket.upload_file('test.manifest', f'{manifest_path}/test.manifest')\n",
    "print('Test manifest uploaded to:\\n' + f\"s3://{bucket.name}/{manifest_path}/test.manifest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create Hyperparameter Tuning Job\n",
    "\n",
    "Now, you are ready to finetune MXNet YOLO model with *train.manifest* and *test.manifest* datasets.\n",
    "\n",
    "Of course, you create hyperparameter tuning job on AWS Console but there is much easier way to do the same job on sagemaker notebook.\n",
    "\n",
    "Sagemaker provide *sagemaker.mxnet.MXNet* estimator to train model. With this class you can train or make hyperparameter tuning job for your own model.\n",
    "\n",
    "First of all, you should define metric for estimator. The estimator's goal is mininize or maximize the metric you gave to it.\n",
    "\n",
    "In this chapter we are going to use *Loss* as a metric which means the goal of the estimator is going to be minize it as much as it can. \n",
    "\n",
    "The estimator container will automatically capture it's *stdout* and find the *Regex* pattern you difined and make it as metric to minize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    { 'Name': 'TrainLoss', 'Regex': 'Train Loss: (.*?) ;' },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have execution role for sagemaker just put it to the *role_name* on below cell.\n",
    "\n",
    "Let's make IAM role on [**AWS Console**]() with *AmazonSagemakerFullAccess* Policy like below screen. \n",
    "\n",
    "<img src=\"Assets/ExecutionRole.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'role_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# replace role_name with yours\n",
    "role_name = 'AmazonSageMaker-ExecutionRole-20200129T183159'\n",
    "%store role_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = iam.get_role(RoleName=role_name)['Role']['Arn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make estiamtor. Estimator handles end-to-end Amazon SageMaker training and deployment tasks.\n",
    "\n",
    "You can run your training job on *Spot Instance* and we are going to do that, because using spot instance is the most cost efficient way to run your job on AWS.\n",
    "\n",
    "The estimator we are making, uses *4 of ml.p3.8xlarge Spot instances* for training so that 4 Hyperparameter tuning job is able to run cucurrently.\n",
    "\n",
    "Let me explain some important parameters before run the code,\n",
    "\n",
    "* entry_point - python script that includes train/finetune logics.\n",
    "* source_dir - local folder location that `entry_point` is placed.\n",
    "* frame_work_version - MXNet framework version\n",
    "* input_mode - 'File' or 'Pipe'. entry_point should be implemented considering input_mode.\n",
    "* train_use_spot_instances - True if you want to use spot-instance for running training jobs.\n",
    "* output_path - s3 bucket path that models and checkpoints will be stored.\n",
    "* hyperparameters - default hyperparameters. most of the values will be overriden by hyperparameter tuning job. (look into *hyperparameter_ranges* variable below cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_output_path' (str)\n"
     ]
    }
   ],
   "source": [
    "model_output_path = f's3://{BUCKET_NAME}/{MODELS_PREFIX}'\n",
    "%store model_output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = MXNet(\n",
    "    role=role,\n",
    "    entry_point='yolo_finetune.py',\n",
    "    source_dir='src',\n",
    "    framework_version='1.6.0',\n",
    "    py_version='py3',\n",
    "    input_mode='File',\n",
    "    train_volume_size=n_samples_train,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.p3.8xlarge',\n",
    "    train_max_run=5*60*60,\n",
    "    train_use_spot_instances=True,\n",
    "    train_max_wait=5*60*60,\n",
    "    metric_definitions=metric_definitions,\n",
    "    base_job_name='yolo-finetune-0',\n",
    "    output_path=model_output_path,\n",
    "    hyperparameters={\n",
    "        'epochs': 30,\n",
    "        'num-workers': 4,\n",
    "        'batch-size': 8,\n",
    "        'num-gpus': 4,\n",
    "        'data-shape': 320,\n",
    "        'lr': 0.000361,\n",
    "        'momentum': 0.299848,\n",
    "        'wd': 0.986724,\n",
    "        'optimizer': 'sgd',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prepare channel\n",
    "\n",
    "HyperParameter tuning job requires data channel for fetch data from s3.\n",
    "\n",
    "Estimator on *File* mode, *image_channel* must be provided to the tuner because Sagemaker training container copies all train/test images on creating container instance using *image_channel*.\n",
    "\n",
    "We are using *File* mode because our dataset is small enough but if you are planning to deal with very large dataset consider *Pipe* mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass only essential keys\n",
    "attribute_names = ['source-ref', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = sagemaker.session.s3_input(\n",
    "    f's3://{BUCKET_NAME}/{manifest_path}/train.manifest',\n",
    "    distribution='FullyReplicated',\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    attribute_names=attribute_names\n",
    ")\n",
    "                                        \n",
    "test_channel = sagemaker.session.s3_input(\n",
    "    f's3://{BUCKET_NAME}/{manifest_path}/test.manifest',\n",
    "    distribution='FullyReplicated',\n",
    "    s3_data_type='S3Prefix',\n",
    "    attribute_names=attribute_names\n",
    ")\n",
    "\n",
    "image_channel = sagemaker.session.s3_input(\n",
    "    f's3://{BUCKET_NAME}/{BATCH_NAME}/{IMAGE_PREFIX}',\n",
    "    s3_data_type=\"S3Prefix\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Finetune Model using Hyperparameter tuning job\n",
    "\n",
    "[How Hyperparameter Tuning Works](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html) says dailed information about hyperparmeter tuning job.\n",
    "\n",
    "Simply put it, hyperparameter tuning job test all of the *likely* parameters in the given range, and find best combination of the parameters for the model with given dataset.\n",
    "\n",
    "In this manner, you should provide ranges of the hyperparameters where the best parameters lie on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    'lr': sagemaker.tuner.ContinuousParameter(0.0001, 0.1),\n",
    "    'momentum': sagemaker.tuner.ContinuousParameter(0.0, 0.99),\n",
    "    'wd': sagemaker.tuner.ContinuousParameter(0.0, 0.99),\n",
    "    'optimizer': sagemaker.tuner.CategoricalParameter(['sgd', 'adam', 'rmsprop', 'adadelta'])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the all together, such as estimator, metric(or loss), hyperparameter ranges, we are going to run Hyperparameter Tuning Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'max_jobs' (int)\n",
      "Stored 'train_start_time' (datetime)\n"
     ]
    }
   ],
   "source": [
    "max_jobs = 12\n",
    "%store max_jobs\n",
    "\n",
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator,\n",
    "    'TrainLoss',\n",
    "    objective_type='Minimize',\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name='yolo-htj-batch-0',\n",
    "    max_jobs=max_jobs,\n",
    "    max_parallel_jobs=2,\n",
    "    early_stopping_type='Auto',\n",
    ")\n",
    "\n",
    "train_start_time = datetime.now()\n",
    "%store train_start_time\n",
    "\n",
    "tuner.fit(\n",
    "    {\n",
    "        \"train\": train_channel,\n",
    "        \"test\": test_channel,\n",
    "        \"images\": image_channel\n",
    "    },\n",
    "    include_cls_metadata=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you call *fit()* method, you can check the progress on [AWS Console](https://console.aws.amazon.com).\n",
    "\n",
    "<img src=\"Assets/TrainingJobStatus.png\" />\n",
    "\n",
    "and, of course, you can check progress out on the notebook using Sagemaker Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'training_job_name' (str)\n"
     ]
    }
   ],
   "source": [
    "# wait for the first job is going to be ready to trating\n",
    "time.sleep(10)\n",
    "\n",
    "training_jobs = smclient.list_training_jobs(NameContains=tuner.base_tuning_job_name, StatusEquals='InProgress')\n",
    "training_job_summaries = training_jobs['TrainingJobSummaries']\n",
    "training_job_name = training_job_summaries[0]['TrainingJobName'].rsplit('-', 2)[0]\n",
    "%store training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>momentum</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>wd</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.256635</td>\n",
       "      <td>\"adam\"</td>\n",
       "      <td>0.918282</td>\n",
       "      <td>yolo-htj-batch-0-200520-1311-006-4a874274</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.977916</td>\n",
       "      <td>\"adam\"</td>\n",
       "      <td>0.672447</td>\n",
       "      <td>yolo-htj-batch-0-200520-1311-005-221ba769</td>\n",
       "      <td>InProgress</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-05-20 13:27:07+09:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.888544</td>\n",
       "      <td>\"adadelta\"</td>\n",
       "      <td>0.984864</td>\n",
       "      <td>yolo-htj-batch-0-200520-1311-004-ba4bc7b8</td>\n",
       "      <td>Completed</td>\n",
       "      <td>31.095583</td>\n",
       "      <td>2020-05-20 13:22:22+09:00</td>\n",
       "      <td>2020-05-20 13:27:31+09:00</td>\n",
       "      <td>309.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.895394</td>\n",
       "      <td>\"adam\"</td>\n",
       "      <td>0.984974</td>\n",
       "      <td>yolo-htj-batch-0-200520-1311-003-e7984609</td>\n",
       "      <td>Completed</td>\n",
       "      <td>12.600845</td>\n",
       "      <td>2020-05-20 13:19:47+09:00</td>\n",
       "      <td>2020-05-20 13:24:13+09:00</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.098679</td>\n",
       "      <td>\"adadelta\"</td>\n",
       "      <td>0.958807</td>\n",
       "      <td>yolo-htj-batch-0-200520-1311-002-1536aa65</td>\n",
       "      <td>Completed</td>\n",
       "      <td>29.863733</td>\n",
       "      <td>2020-05-20 13:14:01+09:00</td>\n",
       "      <td>2020-05-20 13:19:12+09:00</td>\n",
       "      <td>311.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005011</td>\n",
       "      <td>0.658451</td>\n",
       "      <td>\"adadelta\"</td>\n",
       "      <td>0.232507</td>\n",
       "      <td>yolo-htj-batch-0-200520-1311-001-79f8e9a0</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>40.207550</td>\n",
       "      <td>2020-05-20 13:14:45+09:00</td>\n",
       "      <td>2020-05-20 13:17:01+09:00</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  momentum   optimizer        wd  \\\n",
       "0  0.001728  0.256635      \"adam\"  0.918282   \n",
       "1  0.000215  0.977916      \"adam\"  0.672447   \n",
       "2  0.000100  0.888544  \"adadelta\"  0.984864   \n",
       "3  0.000297  0.895394      \"adam\"  0.984974   \n",
       "4  0.000227  0.098679  \"adadelta\"  0.958807   \n",
       "5  0.005011  0.658451  \"adadelta\"  0.232507   \n",
       "\n",
       "                             TrainingJobName TrainingJobStatus  \\\n",
       "0  yolo-htj-batch-0-200520-1311-006-4a874274        InProgress   \n",
       "1  yolo-htj-batch-0-200520-1311-005-221ba769        InProgress   \n",
       "2  yolo-htj-batch-0-200520-1311-004-ba4bc7b8         Completed   \n",
       "3  yolo-htj-batch-0-200520-1311-003-e7984609         Completed   \n",
       "4  yolo-htj-batch-0-200520-1311-002-1536aa65         Completed   \n",
       "5  yolo-htj-batch-0-200520-1311-001-79f8e9a0           Stopped   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0                  NaN                       NaT                       NaT   \n",
       "1                  NaN 2020-05-20 13:27:07+09:00                       NaT   \n",
       "2            31.095583 2020-05-20 13:22:22+09:00 2020-05-20 13:27:31+09:00   \n",
       "3            12.600845 2020-05-20 13:19:47+09:00 2020-05-20 13:24:13+09:00   \n",
       "4            29.863733 2020-05-20 13:14:01+09:00 2020-05-20 13:19:12+09:00   \n",
       "5            40.207550 2020-05-20 13:14:45+09:00 2020-05-20 13:17:01+09:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                       309.0  \n",
       "3                       266.0  \n",
       "4                       311.0  \n",
       "5                       136.0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytics = sagemaker.HyperparameterTuningJobAnalytics(training_job_name)\n",
    "analytics.dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to wait for all training job is completed, it will take around *1 hour*.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_n_completed_jobs(base_job_name, max_jobs):\n",
    "    counts = 0\n",
    "    date_suffix = date.today().strftime('%y%m%d')\n",
    "    job_name = f'{base_job_name}-{date_suffix}'\n",
    "    for status in ['Completed', 'Failed', 'Stopped']:\n",
    "        counts += len(smclient.list_training_jobs(\n",
    "            NameContains=job_name,\n",
    "            StatusEquals=status,\n",
    "            MaxResults=max_jobs,\n",
    "        )['TrainingJobSummaries'])\n",
    "    return counts\n",
    " \n",
    "\n",
    "def wait_for_training(base_job_name, max_jobs):\n",
    "    completed_jobs = 0\n",
    "    while completed_jobs < max_jobs:\n",
    "        print(f'[{base_job_name}] {completed_jobs}/{max_jobs} of training jobs are completed...')\n",
    "        completed_jobs = fetch_n_completed_jobs(base_job_name, max_jobs)\n",
    "        time.sleep(60)\n",
    "    print(f'All({max_jobs}) training jobs are completed!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[yolo-htj-batch-0] 0/12 of training jobs are completed...\n",
      "All(12) training jobs are completed!!\n"
     ]
    }
   ],
   "source": [
    "wait_for_training(tuner.base_tuning_job_name, max_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-20 04:58:07 Starting - Preparing the instances for training\n",
      "2020-05-20 04:58:07 Downloading - Downloading input data\n",
      "2020-05-20 04:58:07 Training - Training image download completed. Training in progress.\n",
      "2020-05-20 04:58:07 Uploading - Uploading generated training model\n",
      "2020-05-20 04:58:07 Completed - Training job completed\u001b[34m2020-05-20 04:54:55,591 sagemaker-containers INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:55,592 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value TrainLoss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:55,638 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch-size\":8,\"data-shape\":320,\"epochs\":24,\"lr\":0.00011262168776049328,\"momentum\":0.07882625227259799,\"num-gpus\":4,\"num-workers\":4,\"optimizer\":\"adam\",\"wd\":0.9368857317913246}', 'SM_USER_ENTRY_POINT': 'yolo_finetune.py', 'SM_FRAMEWORK_PARAMS': '{\"sagemaker_estimator_class_name\":\"MXNet\",\"sagemaker_estimator_module\":\"sagemaker.mxnet.estimator\"}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"images\",\"test\",\"train\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'yolo_finetune', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '32', 'SM_NUM_GPUS': '4', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-ap-northeast-2-929831892372/yolo-finetune-0-2020-05-20-04-11-31-373/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"MXNet\",\"sagemaker_estimator_module\":\"sagemaker.mxnet.estimator\"},\"channel_input_dirs\":{\"images\":\"/opt/ml/input/data/images\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":8,\"data-shape\":320,\"epochs\":24,\"lr\":0.00011262168776049328,\"momentum\":0.07882625227259799,\"num-gpus\":4,\"num-workers\":4,\"optimizer\":\"adam\",\"wd\":0.9368857317913246},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"yolo-htj-batch-0-200520-1311-013-deab1a70\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-929831892372/yolo-finetune-0-2020-05-20-04-11-31-373/source/sourcedir.tar.gz\",\"module_name\":\"yolo_finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"yolo_finetune.py\"}', 'SM_USER_ARGS': '[\"--batch-size\",\"8\",\"--data-shape\",\"320\",\"--epochs\",\"24\",\"--lr\",\"0.00011262168776049328\",\"--momentum\",\"0.07882625227259799\",\"--num-gpus\",\"4\",\"--num-workers\",\"4\",\"--optimizer\",\"adam\",\"--wd\",\"0.9368857317913246\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_IMAGES': '/opt/ml/input/data/images', 'SM_CHANNEL_TEST': '/opt/ml/input/data/test', 'SM_CHANNEL_TRAIN': '/opt/ml/input/data/train', 'SM_HP_LR': '0.00011262168776049328', 'SM_HP_NUM-GPUS': '4', 'SM_HP_DATA-SHAPE': '320', 'SM_HP_WD': '0.9368857317913246', 'SM_HP_MOMENTUM': '0.07882625227259799', 'SM_HP_BATCH-SIZE': '8', 'SM_HP_OPTIMIZER': 'adam', 'SM_HP_NUM-WORKERS': '4', 'SM_HP_EPOCHS': '24'}\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:55,903 sagemaker-containers INFO     Module default_user_module_name does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:55,903 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:55,903 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:55,903 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /tmp/tmphashflzg/module_dir\u001b[0m\n",
      "\u001b[34mInstalling collected packages: default-user-module-name\n",
      "    Running setup.py install for default-user-module-name: started\n",
      "    Running setup.py install for default-user-module-name: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed default-user-module-name-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:58,048 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value TrainLoss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:58,063 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value TrainLoss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:58,107 sagemaker-containers INFO     Failed to parse hyperparameter _tuning_objective_metric value TrainLoss to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m2020-05-20 04:54:58,151 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_estimator_module\": \"sagemaker.mxnet.estimator\",\n",
      "        \"sagemaker_estimator_class_name\": \"MXNet\"\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"images\": \"/opt/ml/input/data/images\",\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"lr\": 0.00011262168776049328,\n",
      "        \"num-gpus\": 4,\n",
      "        \"data-shape\": 320,\n",
      "        \"wd\": 0.9368857317913246,\n",
      "        \"momentum\": 0.07882625227259799,\n",
      "        \"batch-size\": 8,\n",
      "        \"optimizer\": \"adam\",\n",
      "        \"num-workers\": 4,\n",
      "        \"epochs\": 24\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"images\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"yolo-htj-batch-0-200520-1311-013-deab1a70\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-2-929831892372/yolo-finetune-0-2020-05-20-04-11-31-373/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"yolo_finetune\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"yolo_finetune.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":8,\"data-shape\":320,\"epochs\":24,\"lr\":0.00011262168776049328,\"momentum\":0.07882625227259799,\"num-gpus\":4,\"num-workers\":4,\"optimizer\":\"adam\",\"wd\":0.9368857317913246}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=yolo_finetune.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_estimator_class_name\":\"MXNet\",\"sagemaker_estimator_module\":\"sagemaker.mxnet.estimator\"}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"images\",\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=yolo_finetune\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-2-929831892372/yolo-finetune-0-2020-05-20-04-11-31-373/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_estimator_class_name\":\"MXNet\",\"sagemaker_estimator_module\":\"sagemaker.mxnet.estimator\"},\"channel_input_dirs\":{\"images\":\"/opt/ml/input/data/images\",\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":8,\"data-shape\":320,\"epochs\":24,\"lr\":0.00011262168776049328,\"momentum\":0.07882625227259799,\"num-gpus\":4,\"num-workers\":4,\"optimizer\":\"adam\",\"wd\":0.9368857317913246},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"images\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"yolo-htj-batch-0-200520-1311-013-deab1a70\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-2-929831892372/yolo-finetune-0-2020-05-20-04-11-31-373/source/sourcedir.tar.gz\",\"module_name\":\"yolo_finetune\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"yolo_finetune.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"8\",\"--data-shape\",\"320\",\"--epochs\",\"24\",\"--lr\",\"0.00011262168776049328\",\"--momentum\",\"0.07882625227259799\",\"--num-gpus\",\"4\",\"--num-workers\",\"4\",\"--optimizer\",\"adam\",\"--wd\",\"0.9368857317913246\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_IMAGES=/opt/ml/input/data/images\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.00011262168776049328\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-GPUS=4\u001b[0m\n",
      "\u001b[34mSM_HP_DATA-SHAPE=320\u001b[0m\n",
      "\u001b[34mSM_HP_WD=0.9368857317913246\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.07882625227259799\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=8\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZER=adam\u001b[0m\n",
      "\u001b[34mSM_HP_NUM-WORKERS=4\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=24\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 yolo_finetune.py --batch-size 8 --data-shape 320 --epochs 24 --lr 0.00011262168776049328 --momentum 0.07882625227259799 --num-gpus 4 --num-workers 4 --optimizer adam --wd 0.9368857317913246\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mCollecting Cython\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/bb/a5fa1fae3fc5412d79fce8d984cf96e1351685cdd60f289952b722a96cc8/Cython-0.29.18-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: Cython\n",
      "  Found existing installation: Cython 0.29.16\n",
      "    Uninstalling Cython-0.29.16:\u001b[0m\n",
      "\u001b[34m      Successfully uninstalled Cython-0.29.16\u001b[0m\n",
      "\u001b[34mSuccessfully installed Cython-0.29.18\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34mCollecting gluoncv\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/81/37a00609cb53da3671adb106b9bc03fb1c029ad5a8db4bc668283e65703d/gluoncv-0.7.0-py2.py3-none-any.whl (752kB)\u001b[0m\n",
      "\u001b[34mCollecting pycocotools\u001b[0m\n",
      "\u001b[34m  Downloading https://files.pythonhosted.org/packages/96/84/9a07b1095fd8555ba3f3d519517c8743c2554a245f9476e5e39869f948d2/pycocotools-2.0.0.tar.gz (1.5MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/site-packages (from gluoncv) (2.22.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/site-packages (from gluoncv) (1.2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/site-packages (from gluoncv) (1.17.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/site-packages (from gluoncv) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: portalocker in /usr/local/lib/python3.6/site-packages (from gluoncv) (1.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.6/site-packages (from gluoncv) (7.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/site-packages (from gluoncv) (4.39.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv) (2019.11.28)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv) (2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests->gluoncv) (1.25.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv) (2.4.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv) (2.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/site-packages (from matplotlib->gluoncv) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/site-packages (from cycler>=0.10->matplotlib->gluoncv) (1.14.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: gluoncv, pycocotools\n",
      "  Found existing installation: gluoncv 0.6.0\n",
      "    Uninstalling gluoncv-0.6.0:\n",
      "      Successfully uninstalled gluoncv-0.6.0\u001b[0m\n",
      "\u001b[34m    Running setup.py install for pycocotools: started\u001b[0m\n",
      "\u001b[34m    Running setup.py install for pycocotools: finished with status 'done'\u001b[0m\n",
      "\u001b[34mSuccessfully installed gluoncv-0.7.0 pycocotools-2.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3.1; however, version 20.1.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/images/103.jpg', '/opt/ml/input/data/images/97.jpg', '/opt/ml/input/data/images/82.jpg', '/opt/ml/input/data/images/70.jpg', '/opt/ml/input/data/images/16.jpg', '/opt/ml/input/data/images/28.jpg', '/opt/ml/input/data/images/34.jpg', '/opt/ml/input/data/images/4.jpg', '/opt/ml/input/data/images/49.jpg', '/opt/ml/input/data/images/109.jpg', '/opt/ml/input/data/images/91.jpg', '/opt/ml/input/data/images/7.jpg', '/opt/ml/input/data/images/73.jpg', '/opt/ml/input/data/images/43.jpg', '/opt/ml/input/data/images/1.jpg', '/opt/ml/input/data/images/10.jpg', '/opt/ml/input/data/images/61.jpg', '/opt/ml/input/data/images/118.jpg', '/opt/ml/input/data/images/55.jpg', '/opt/ml/input/data/images/19.jpg', '/opt/ml/input/data/images/46.jpg', '/opt/ml/input/data/images/88.jpg', '/opt/ml/input/data/images/37.jpg', '/opt/ml/input/data/images/79.jpg', '/opt/ml/input/data/images/112.jpg', '/opt/ml/input/data/images/76.jpg', '/opt/ml/input/data/images/25.jpg', '/opt/ml/input/data/images/85.jpg', '/opt/ml/input/data/images/31.jpg', '/opt/ml/input/data/images/121.jpg', '/opt/ml/input/data/images/22.jpg', '/opt/ml/input/data/images/58.jpg', '/opt/ml/input/data/images/115.jpg', '/opt/ml/input/data/images/100.jpg', '/opt/ml/input/data/images/40.jpg', '/opt/ml/input/data/images/94.jpg', '/opt/ml/input/data/images/64.jpg', '/opt/ml/input/data/images/106.jpg', '/opt/ml/input/data/images/52.jpg', '/opt/ml/input/data/images/67.jpg', '/opt/ml/input/data/images/13.jpg']\u001b[0m\n",
      "\u001b[34mDownloading /root/.mxnet/models/yolo3_darknet53_coco-09767802.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/yolo3_darknet53_coco-09767802.zip...\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0/224190 [00:00<?, ?KB/s]#015  0%|          | 26/224190 [00:00<17:30, 213.40KB/s]#015  0%|          | 94/224190 [00:00<14:17, 261.28KB/s]#015  0%|          | 244/224190 [00:00<10:55, 341.44KB/s]#015  0%|          | 515/224190 [00:00<08:09, 456.52KB/s]#015  0%|          | 888/224190 [00:00<06:04, 612.68KB/s]#015  1%|          | 1389/224190 [00:00<04:30, 822.43KB/s]#015  1%|         | 2813/224190 [00:00<03:14, 1140.40KB/s]#015  2%|         | 4157/224190 [00:00<02:21, 1558.62KB/s]#015  4%|         | 8317/224190 [00:01<01:38, 2182.85KB/s]#015  6%|         | 12413/224190 [00:01<01:09, 3033.34KB/s]#015  8%|         | 17293/224190 [00:01<00:49, 4220.87KB/s]#015  9%|         | 21097/224190 [00:01<00:35, 5756.09KB/s]#015 11%|         | 25157/224190 [00:01<00:25, 7751.88KB/s]#015 13%|        | 28920/224190 [00:01<00:19, 10175.72KB/s]#015 15%|        | 32676/224190 [00:01<00:14, 13024.34KB/s]#015 17%|        | 37473/224190 [00:01<00:11, 16666.69KB/s]#015 18%|        | 41432/224190 [00:01<00:09, 20080.83KB/s]#015 20%|        | 45445/224190 [00:02<00:07, 23575.16KB/s]#015 22%|       | 49383/224190 [00:02<00:06, 26260.18KB/s]#015 24%|       | 53369/224190 [00:02<00:05, 29254.10KB/s]#015 26%|       | 57537/224190 [00:02<00:05, 31816.73KB/s]#015 27%|       | 61642/224190 [00:02<00:04, 34118.05KB/s]#015 29%|       | 65613/224190 [00:02<00:04, 35093.18KB/s]#015 31%|       | 69521/224190 [00:02<00:04, 35958.61KB/s]#015 33%|      | 73866/224190 [00:02<00:03, 37918.37KB/s]#015 35%|      | 77886/224190 [00:02<00:03, 37951.54KB/s]#015 37%|      | 82267/224190 [00:02<00:03, 39537.06KB/s]#015 39%|      | 86350/224190 [00:03<00:03, 39238.51KB/s]#015 40%|      | 90365/224190 [00:03<00:03, 38294.40KB/s]#015 42%|     | 94287/224190 [00:03<00:03, 38564.89KB/s]#015 44%|     | 98641/224190 [00:03<00:03, 39931.67KB/s]#015 46%|     | 102761/224190 [00:03<00:03, 40010.21KB/s]#015 48%|     | 106982/224190 [00:03<00:02, 40644.19KB/s]#015 50%|     | 111072/224190 [00:03<00:02, 39958.83KB/s]#015 51%|    | 115089/224190 [00:03<00:02, 39554.80KB/s]#015 53%|    | 119060/224190 [00:03<00:02, 39341.59KB/s]#015 55%|    | 123276/224190 [00:04<00:02, 40146.36KB/s]#015 57%|    | 127588/224190 [00:04<00:02, 40993.10KB/s]#015 59%|    | 131700/224190 [00:04<00:02, 39798.84KB/s]#015 61%|    | 135697/224190 [00:04<00:02, 39187.61KB/s]#015 62%|   | 139634/224190 [00:04<00:02, 39239.42KB/s]#015 64%|   | 143851/224190 [00:04<00:02, 39775.07KB/s]#015 66%|   | 148171/224190 [00:04<00:01, 40332.17KB/s]#015 68%|   | 152212/224190 [00:04<00:01, 39941.33KB/s]#015 70%|   | 156213/224190 [00:04<00:01, 39685.47KB/s]#015 71%|  | 160211/224190 [00:04<00:01, 39771.48KB/s]#015 73%|  | 164192/224190 [00:05<00:01, 39215.52KB/s]#015 75%|  | 168459/224190 [00:05<00:01, 39738.13KB/s]#015 77%|  | 172711/224190 [00:05<00:01, 40533.69KB/s]#015 79%|  | 176772/224190 [00:05<00:01, 39366.03KB/s]#015 81%|  | 180721/224190 [00:05<00:01, 36980.99KB/s]#015 82%| | 184939/224190 [00:05<00:01, 37883.20KB/s]#015 84%| | 188760/224190 [00:05<00:01, 28446.07KB/s]#015 86%| | 193195/224190 [00:05<00:00, 31162.13KB/s]#015 88%| | 196648/224190 [00:06<00:00, 29182.79KB/s]#015 90%| | 201019/224190 [00:06<00:00, 30828.51KB/s]#015 91%| | 204310/224190 [00:06<00:00, 29536.06KB/s]#015 93%|| 207755/224190 [00:06<00:00, 29799.78KB/s]#015 95%|| 211899/224190 [00:06<00:00, 30897.86KB/s]#015 97%|| 216811/224190 [00:06<00:00, 32894.93KB/s]#015 99%|| 221467/224190 [00:06<00:00, 34410.47KB/s]#015100%|| 224190/224190 [00:06<00:00, 32887.88KB/s]\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mDone (t=0.00s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mloading annotations into memory...\u001b[0m\n",
      "\u001b[34mDone (t=0.00s)\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:Start training\u001b[0m\n",
      "\u001b[34m[04:55:52] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 0] Train Loss: 17.274282693862915 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 0] Train Cost: 7.938, ObjLoss=9.576, BoxCenterLoss=5.723, BoxScaleLoss=1.536, ClassLoss=0.439\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 17.274283, previous best loss: inf\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 1] Train Loss: 14.160190463066101 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 1] Train Cost: 3.638, ObjLoss=7.141, BoxCenterLoss=5.501, BoxScaleLoss=1.227, ClassLoss=0.290\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 14.160190, previous best loss: 17.274283\u001b[0m\n",
      "\u001b[34m[04:56:05] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 2] Train Loss: 14.277697335590016 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 2] Train Cost: 7.079, ObjLoss=7.161, BoxCenterLoss=5.690, BoxScaleLoss=1.209, ClassLoss=0.219\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 3] Train Loss: 13.603262678782146 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 3] Train Cost: 2.317, ObjLoss=6.829, BoxCenterLoss=5.422, BoxScaleLoss=1.189, ClassLoss=0.163\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 13.603263, previous best loss: 14.160190\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 4] Train Loss: 13.250268277369047 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 4] Train Cost: 3.558, ObjLoss=6.460, BoxCenterLoss=5.460, BoxScaleLoss=1.196, ClassLoss=0.135\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 13.250268, previous best loss: 13.603263\u001b[0m\n",
      "\u001b[34m[04:56:20] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 5] Train Loss: 13.193076543186022 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 5] Train Cost: 7.658, ObjLoss=6.320, BoxCenterLoss=5.566, BoxScaleLoss=1.191, ClassLoss=0.116\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 13.193077, previous best loss: 13.250268\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 6] Train Loss: 12.802104307545555 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 6] Train Cost: 3.301, ObjLoss=6.049, BoxCenterLoss=5.506, BoxScaleLoss=1.147, ClassLoss=0.101\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 12.802104, previous best loss: 13.193077\u001b[0m\n",
      "\u001b[34m[04:56:31] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 7] Train Loss: 12.48805220088651 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 7] Train Cost: 3.537, ObjLoss=5.834, BoxCenterLoss=5.448, BoxScaleLoss=1.117, ClassLoss=0.089\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 12.488052, previous best loss: 12.802104\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 8] Train Loss: 12.313802240525975 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 8] Train Cost: 2.111, ObjLoss=5.682, BoxCenterLoss=5.457, BoxScaleLoss=1.093, ClassLoss=0.082\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 12.313802, previous best loss: 12.488052\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 9] Train Loss: 11.970955825165698 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 9] Train Cost: 2.127, ObjLoss=5.464, BoxCenterLoss=5.367, BoxScaleLoss=1.063, ClassLoss=0.077\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 11.970956, previous best loss: 12.313802\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 10] Train Loss: 11.779134638252712 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 10] Train Cost: 3.496, ObjLoss=5.284, BoxCenterLoss=5.388, BoxScaleLoss=1.036, ClassLoss=0.070\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 11.779135, previous best loss: 11.970956\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 11] Train Loss: 11.527786012576973 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 11] Train Cost: 2.345, ObjLoss=5.071, BoxCenterLoss=5.373, BoxScaleLoss=1.019, ClassLoss=0.064\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 11.527786, previous best loss: 11.779135\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 12] Train Loss: 11.41913757443428 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 12] Train Cost: 2.422, ObjLoss=4.954, BoxCenterLoss=5.406, BoxScaleLoss=0.999, ClassLoss=0.060\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 11.419138, previous best loss: 11.527786\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 13] Train Loss: 11.159974609260205 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 13] Train Cost: 2.441, ObjLoss=4.751, BoxCenterLoss=5.373, BoxScaleLoss=0.980, ClassLoss=0.056\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 11.159975, previous best loss: 11.419138\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 14] Train Loss: 11.034587978289045 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 14] Train Cost: 2.425, ObjLoss=4.634, BoxCenterLoss=5.371, BoxScaleLoss=0.977, ClassLoss=0.052\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 11.034588, previous best loss: 11.159975\u001b[0m\n",
      "\u001b[34m[04:56:59] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 15] Train Loss: 10.961850319177874 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 15] Train Cost: 7.512, ObjLoss=4.604, BoxCenterLoss=5.344, BoxScaleLoss=0.964, ClassLoss=0.050\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.961850, previous best loss: 11.034588\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 16] Train Loss: 10.970182238175319 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 16] Train Cost: 2.217, ObjLoss=4.593, BoxCenterLoss=5.371, BoxScaleLoss=0.958, ClassLoss=0.048\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 17] Train Loss: 10.832378735576851 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 17] Train Cost: 5.128, ObjLoss=4.501, BoxCenterLoss=5.335, BoxScaleLoss=0.951, ClassLoss=0.045\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.832379, previous best loss: 10.961850\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 18] Train Loss: 10.741939971708272 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 18] Train Cost: 2.376, ObjLoss=4.453, BoxCenterLoss=5.305, BoxScaleLoss=0.941, ClassLoss=0.044\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.741940, previous best loss: 10.832379\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 19] Train Loss: 10.69014651666988 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 19] Train Cost: 2.480, ObjLoss=4.404, BoxCenterLoss=5.298, BoxScaleLoss=0.947, ClassLoss=0.041\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.690147, previous best loss: 10.741940\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 20] Train Loss: 10.596935056609873 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 20] Train Cost: 2.666, ObjLoss=4.299, BoxCenterLoss=5.318, BoxScaleLoss=0.941, ClassLoss=0.040\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.596935, previous best loss: 10.690147\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 21] Train Loss: 10.56724681784125 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 21] Train Cost: 2.506, ObjLoss=4.229, BoxCenterLoss=5.365, BoxScaleLoss=0.936, ClassLoss=0.038\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.567247, previous best loss: 10.596935\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 22] Train Loss: 10.530447341752856 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 22] Train Cost: 2.264, ObjLoss=4.171, BoxCenterLoss=5.388, BoxScaleLoss=0.935, ClassLoss=0.036\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.530447, previous best loss: 10.567247\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 23] Train Loss: 10.498750421949612 ;\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:[Epoch 23] Train Cost: 2.393, ObjLoss=4.146, BoxCenterLoss=5.390, BoxScaleLoss=0.928, ClassLoss=0.035\u001b[0m\n",
      "\u001b[34mINFO:yolo3_darknet53:save model with current loss: 10.498750, previous best loss: 10.530447\u001b[0m\n",
      "\u001b[34m2020-05-20 04:57:29,022 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 228\n",
      "Billable seconds: 68\n",
      "Managed Spot Training savings: 70.2%\n"
     ]
    }
   ],
   "source": [
    "best_estimator = tuner.best_estimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'best_model_job_name' (str)\n",
      "Stored 'best_model_output_path' (str)\n"
     ]
    }
   ],
   "source": [
    "best_model_job_name = best_estimator.base_job_name\n",
    "%store best_model_job_name \n",
    "\n",
    "best_model_output_path = f'{best_estimator.output_path}' \n",
    "%store best_model_output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we got the finetuned model. In next notebook, we are going to deploy this model to *Sagemaker Endpoint* so that you can detect objects through calling REST API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
